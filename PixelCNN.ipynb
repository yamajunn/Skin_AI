{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple PixelCNN model for RGBA images\n",
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, channels=4, kernel_size=7, hidden_dim=64):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, hidden_dim, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(hidden_dim, hidden_dim, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(hidden_dim, channels * 256, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBADataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.data = []\n",
    "        for file_path in file_paths:\n",
    "            image = np.array(Image.open(file_path).convert(\"RGBA\"))\n",
    "            self.data.append(image)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        image_pil = Image.fromarray(np.uint8(image * 255))  # Convert to PIL Image\n",
    "        if self.transform:\n",
    "            image_pil = self.transform(image_pil)\n",
    "        return image_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, device, num_images=10, channels=4, height=64, width=64):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images = torch.zeros(num_images, channels, height, width).to(device)\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                out = model(images)\n",
    "                out = torch.softmax(out, dim=1)  # Apply softmax to convert to probability distribution\n",
    "                pixel = torch.multinomial(out[:, :, i, j], 1).float() / 255.0\n",
    "                images[:, :, i, j] = pixel.view(1, 1, 1)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "def train_pixelcnn(model, dataloader, optimizer, criterion, num_epochs=10, device=\"cuda\"):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for data in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
    "            optimizer.zero_grad()\n",
    "            images = data.to(device)\n",
    "            output = model(images)\n",
    "            loss = criterion(output.permute(0, 2, 3, 1).contiguous().view(-1, 256), images.permute(0, 2, 3, 1).contiguous().view(-1).long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_path = \"SkinData/data/alex/\"\n",
    "file_paths = [os.path.join(data_path, f) for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f))]\n",
    "\n",
    "# Dataset and DataLoader setup\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = RGBADataset(file_paths, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, optimizer, and criterion setup\n",
    "model = PixelCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 42/42 [00:02<00:00, 14.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 3.9054746741340276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 42/42 [00:02<00:00, 15.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 1.074300487836202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 42/42 [00:02<00:00, 16.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.23065844218113593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 42/42 [00:02<00:00, 17.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.014797886822461373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 42/42 [00:02<00:00, 16.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.0053996066313369995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 42/42 [00:02<00:00, 18.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.003313058412112739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 42/42 [00:02<00:00, 17.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.0022871732417981895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 42/42 [00:02<00:00, 18.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0016935282259336894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 42/42 [00:02<00:00, 16.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.001319630747145441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 42/42 [00:02<00:00, 18.15batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.001055424758219271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_pixelcnn(model, dataloader, optimizer, criterion, num_epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display images\n",
    "generated = generate_images(model, device, num_images=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 1.0039, 3.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 3.0118,  ..., 0.0000, 3.0118, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 1.0039, 3.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 3.0118,  ..., 0.0000, 3.0118, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 1.0039, 3.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 3.0118,  ..., 0.0000, 3.0118, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 1.0039, 3.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 3.0118,  ..., 0.0000, 3.0118, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(generated[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画像を正規化\n",
    "image_tensor = generated / 2\n",
    "# NumPy配列に変換して表示\n",
    "image = image_tensor[0].cpu().numpy().transpose(1, 2, 0)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
