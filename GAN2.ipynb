{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generatorの定義\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 64*64*4),  # RGBA画像のサイズに合わせる\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 4, 64, 64)  # RGBA画像の形式に変換\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminatorの定義\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(64*64*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGBADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(root, f) for f in os.listdir(root) if os.path.isfile(os.path.join(root, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGBA\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = RGBADataset(root=\"SkinData/data/alex/\", transform=transform)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] [Batch 1/3] [D loss: 0.09200656414031982] [G loss: 2.770547389984131]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/10] [Batch 2/3] [D loss: 0.13846455514431] [G loss: 1.8325068950653076]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ハイパーパラメータ\n",
    "latent_dim = 10\n",
    "lr = 0.0003\n",
    "batch_size = 20\n",
    "n_epochs = 10\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# モデルの初期化\n",
    "generator = Generator(latent_dim)\n",
    "discriminator = Discriminator()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "# 損失関数と最適化手法の定義\n",
    "adversarial_loss = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "images = np.array([])\n",
    "# 学習ループ\n",
    "for epoch in range(n_epochs):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "        real_imgs = imgs.to(device)\n",
    "        # Generatorの学習\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), torch.ones(batch_size, 1).to(device))\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        real_labels = torch.ones(real_imgs.size(0), 1).to(device)\n",
    "        fake_labels = torch.zeros(gen_imgs.size(0), 1).to(device)\n",
    "\n",
    "        # Discriminatorの学習\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real_labels)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake_labels)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        print(f\"\\r[Epoch {epoch}/{n_epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\",end=\"\")\n",
    "\n",
    "z = torch.randn(25, latent_dim)\n",
    "gen_imgs = generator(z)\n",
    "gen_imgs = gen_imgs.view(gen_imgs.size(0), 4, 64, 64)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(gen_imgs[gen_imgs.size(0)-1].cpu().detach().numpy().transpose(1, 2, 0))\n",
    "plt.axis('off')\n",
    "\n",
    "dir_path = \"Created_Skin/\"\n",
    "files = os.listdir(dir_path)\n",
    "img = cv2.cvtColor(gen_imgs[gen_imgs.size(0)-1].cpu().detach().numpy().transpose(1, 2, 0)*255, cv2.COLOR_RGB2BGRA)\n",
    "cv2.imwrite(f\"{dir_path}ai_{len(files)+1}.png\", img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = torch.randn(25, latent_dim)\n",
    "# gen_imgs = generator(z)\n",
    "# gen_imgs = gen_imgs.view(gen_imgs.size(0), 4, 64, 64)\n",
    "# plt.figure(figsize=(200, 200))\n",
    "# for k in range(gen_imgs.size(0)):\n",
    "#     plt.subplot(25, 1, k+1)\n",
    "#     plt.imshow(gen_imgs[k].cpu().detach().numpy().transpose(1, 2, 0))\n",
    "#     plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_process(hist, G, image_frame_dim, sample_z_, fix=True):\n",
    "    plt.gcf().clear()\n",
    "\n",
    "    fig = plt.figure(figsize=(24, 15))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    x = range(len(hist['D_loss']))\n",
    "\n",
    "    y1 = hist['D_loss']\n",
    "    y2 = hist['G_loss']\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "    ax1.plot(x, y1, label='D_loss')\n",
    "    ax1.plot(x, y2, label='G_loss')\n",
    "\n",
    "    ax1.set_xlabel('Iter')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    ax1.legend(loc=4)\n",
    "    ax1.grid(True)\n",
    "\n",
    "    samples = G(sample_z_)\n",
    "    samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
    "    samples = (samples + 1) / 2\n",
    "\n",
    "    for i in range(image_frame_dim*image_frame_dim):\n",
    "        ax = fig.add_subplot(image_frame_dim, image_frame_dim*2, (int(i/image_frame_dim)+1)*image_frame_dim+i+1, xticks=[], yticks=[])\n",
    "        if samples[i].shape[2]==3:\n",
    "            ax.imshow(samples[i])\n",
    "        else:\n",
    "            ax.imshow(samples[i][:, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralNorm(nn.Module):\n",
    "    def __init__(self, module, name='weight', power_iterations=1):\n",
    "        super(SpectralNorm, self).__init__()\n",
    "        self.module = module\n",
    "        self.name = name\n",
    "        self.power_iterations = power_iterations\n",
    "        if not self._made_params():\n",
    "            self._make_params()\n",
    "\n",
    "    def _update_u_v(self):\n",
    "        u = getattr(self.module, self.name + \"_u\")\n",
    "        v = getattr(self.module, self.name + \"_v\")\n",
    "        w = getattr(self.module, self.name + \"_bar\")\n",
    "\n",
    "        height = w.data.shape[0]\n",
    "        for _ in range(self.power_iterations):\n",
    "            # vベクトルの更新\n",
    "            # https://pytorch.org/docs/stable/generated/torch.mv.html\n",
    "            v.data = self._l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
    "            # uベクトルの更新\n",
    "            u.data = self._l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
    "\n",
    "        sigma = u.dot(w.view(height, -1).mv(v))\n",
    "        # レイヤーのWをW_SNに置き換える\n",
    "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
    "\n",
    "    def _made_params(self):\n",
    "        try:\n",
    "            u = getattr(self.module, self.name + \"_u\")\n",
    "            v = getattr(self.module, self.name + \"_v\")\n",
    "            w = getattr(self.module, self.name + \"_bar\")\n",
    "            return True\n",
    "        except AttributeError:\n",
    "            return False\n",
    "\n",
    "    def _make_params(self):\n",
    "        w = getattr(self.module, self.name)\n",
    "\n",
    "        # Conv2dのweight matrixは4次元\n",
    "        height = w.data.shape[0]\n",
    "        width = w.view(height, -1).data.shape[1]\n",
    "\n",
    "        # new()で同じdtypeの新しいTensorを作り，normal_(mean, std)で初期化\n",
    "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False) # ( h, )\n",
    "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False) # ( w, )\n",
    "        u.data = self._l2normalize(u.data)\n",
    "        v.data = self._l2normalize(v.data)\n",
    "        w_bar = Parameter(w.data)\n",
    "\n",
    "        del self.module._parameters[self.name]\n",
    "\n",
    "        self.module.register_parameter(self.name + \"_u\", u)\n",
    "        self.module.register_parameter(self.name + \"_v\", v)\n",
    "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
    "\n",
    "    def _l2normalize(self, v, eps=1e-12):\n",
    "        return v / (v.norm() + eps)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        self._update_u_v()\n",
    "        return self.module.forward(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sngan_discriminator(nn.Module):\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=32):\n",
    "        super(sngan_discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            SpectralNorm(nn.Conv2d(self.input_dim, 64, 3, stride=1, padding=(1,1))),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            SpectralNorm(nn.Conv2d(64, 64, 4, stride=2, padding=(1,1))),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            SpectralNorm(nn.Conv2d(64, 128, 3, stride=1, padding=(1,1))),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            SpectralNorm(nn.Conv2d(128, 128, 4, stride=2, padding=(1,1))),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            SpectralNorm(nn.Conv2d(128, 256, 3, stride=1, padding=(1,1))),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            SpectralNorm(nn.Linear(256 * (self.input_size//4) * (self.input_size//4), self.output_dim)),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x.view(-1, 256 * (self.input_size//4) * (self.input_size//4)))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavierの初期化, Heの初期化など採用するネットワーク構造, 活性化関数に合わせた初期化手法は多数\n",
    "def initialize_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self, input_dim=100, output_dim=1, input_size=32):\n",
    "        super(generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            # https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.fc(input)\n",
    "        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n",
    "        x = self.deconv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNGAN(object):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        self.epoch = 3\n",
    "        self.sample_num = 20\n",
    "        self.batch_size = 2\n",
    "        self.input_size = 28\n",
    "        self.z_dim = 62\n",
    "        self.lrG = 0.0002\n",
    "        self.lrD = 0.0002\n",
    "        self.beta1 = 0.5\n",
    "        self.beta2 = 0.999\n",
    "        self.dataset = dataset # mnist, fashion-mnist, cifar10\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        dataset = RGBADataset(root=\"SkinData/data/alex/\", transform=transform)\n",
    "        self.data_loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        data = self.data_loader.__iter__().__next__()[0]\n",
    "\n",
    "        # networks init\n",
    "        self.G = generator(input_dim=self.z_dim, output_dim=data.shape[1], input_size=self.input_size)\n",
    "        self.D = sngan_discriminator(input_dim=data.shape[1], output_dim=1, input_size=self.input_size)\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=self.lrG, betas=(self.beta1, self.beta2))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=self.lrD, betas=(self.beta1, self.beta2))\n",
    "\n",
    "        self.G\n",
    "        self.D\n",
    "        self.BCE_loss = nn.BCELoss()\n",
    "\n",
    "        self.sample_z_ = torch.rand((self.batch_size, self.z_dim))\n",
    "        self.sample_z_ = self.sample_z_\n",
    "\n",
    "    def train(self):\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "\n",
    "        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n",
    "        self.y_real_, self.y_fake_ = self.y_real_, self.y_fake_\n",
    "\n",
    "        self.D.train()\n",
    "        for epoch in range(self.epoch):\n",
    "            self.G.train()\n",
    "            for iter, x_ in enumerate(self.data_loader):\n",
    "                # if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
    "                    # break\n",
    "\n",
    "                z_ = torch.rand((self.batch_size, self.z_dim))\n",
    "                x_, z_ = x_, z_\n",
    "\n",
    "                # update D network\n",
    "                self.D_optimizer.zero_grad()\n",
    "\n",
    "                D_real = self.D(x_)\n",
    "                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n",
    "\n",
    "                G_ = self.G(z_)\n",
    "                D_fake = self.D(G_)\n",
    "                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n",
    "\n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                self.train_hist['D_loss'].append(D_loss.item())\n",
    "\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                # update G network\n",
    "                self.G_optimizer.zero_grad()\n",
    "\n",
    "                G_ = self.G(z_)\n",
    "                D_fake = self.D(G_)\n",
    "                G_loss = self.BCE_loss(D_fake, self.y_real_)\n",
    "                self.train_hist['G_loss'].append(G_loss.item())\n",
    "\n",
    "                G_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "\n",
    "                print(iter)\n",
    "                if ((iter + 1) % 10) == 0:\n",
    "                    with torch.no_grad():\n",
    "                        tot_num_samples = min(self.sample_num, self.batch_size)\n",
    "                        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n",
    "                        display_process(self.train_hist, self.G, image_frame_dim, self.sample_z_)\n",
    "                        display.clear_output(wait=True)\n",
    "                        display.display(pl.gcf())\n",
    "                        plt.close()\n",
    "\n",
    "        plt.close()\n",
    "        print(\"Training finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 64, 3, 3], expected input[2, 4, 64, 64] to have 64 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sngan \u001b[38;5;241m=\u001b[39m SNGAN()  \u001b[38;5;66;03m# 他のデータセットで学習する場合: SNGAN(dataset='fashion-mnist'), SNGAN(dataset='cifar10'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msngan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [74], line 56\u001b[0m, in \u001b[0;36mSNGAN.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# update D network\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 56\u001b[0m D_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m D_real_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBCE_loss(D_real, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_real_)\n\u001b[1;32m     59\u001b[0m G_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG(z_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [48], line 27\u001b[0m, in \u001b[0;36msngan_discriminator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m)))\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [47], line 61\u001b[0m, in \u001b[0;36mSpectralNorm.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_u_v()\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 64, 3, 3], expected input[2, 4, 64, 64] to have 64 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "sngan = SNGAN()  # 他のデータセットで学習する場合: SNGAN(dataset='fashion-mnist'), SNGAN(dataset='cifar10'\n",
    "sngan.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
