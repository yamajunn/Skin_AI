{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 110\u001b[0m\n\u001b[0;32m    104\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m#### 1. データの読み込み\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Fashion-MNIST: MNISTのファッションデータ\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# 60,000 例のトレーニング セットと 10,000 例のテスト セット\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# 28x28 グレースケール イメージで、10 クラスのラベル\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfashion_mnist\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# 複数の前処理を定義, 画像データをテンソルに変換する, 1次元のベクトルに変換するラムダ関数\u001b[39;00m\n\u001b[0;32m    112\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor(),\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GANモデルのクラス\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.G = Generator(device=device)\n",
    "        self.D = Discriminator(device=device)\n",
    "    def forward(self, x):\n",
    "        x = self.G(x)\n",
    "        y = self.D(x)\n",
    "        return y\n",
    "    \n",
    "# 識別器(Generator)のクラス\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.conv1 = nn.Conv2d(1, 128,\n",
    "                               kernel_size=(3, 3),\n",
    "                               stride=(2, 2),\n",
    "                               padding=1)\n",
    "        self.relu1 = nn.LeakyReLU(0.2)\n",
    "        self.conv2 = nn.Conv2d(128, 256,\n",
    "                               kernel_size=(3, 3),\n",
    "                               stride=(2, 2),\n",
    "                               padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.relu2 = nn.LeakyReLU(0.2)\n",
    "        self.fc = nn.Linear(256*7*7, 1024)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.relu3 = nn.LeakyReLU(0.2)\n",
    "        self.out = nn.Linear(1024, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.relu1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = self.relu2(h)\n",
    "        h = h.view(-1, 256*7*7)\n",
    "        h = self.fc(h)\n",
    "        h = self.bn3(h)\n",
    "        h = self.relu3(h)\n",
    "        h = self.out(h)\n",
    "        y = torch.sigmoid(h)\n",
    "        return y\n",
    "\n",
    "# 生成器(Discriminator)のクラス\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=100, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.linear = nn.Linear(input_dim, 256*14*14)\n",
    "        self.bn1 = nn.BatchNorm1d(256*14*14)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(256, 128,\n",
    "                               kernel_size=(3, 3),\n",
    "                               padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(128, 64,\n",
    "                               kernel_size=(3, 3),\n",
    "                               padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(64, 1, kernel_size=(1, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.linear(x)\n",
    "        h = self.bn1(h)\n",
    "        h = self.relu1(h)\n",
    "        h = h.view(-1, 256, 14, 14)\n",
    "        h = F.interpolate(h, size=(28, 28))\n",
    "        h = self.conv1(h)\n",
    "        h = self.bn2(h)\n",
    "        h = self.relu2(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.bn3(h)\n",
    "        h = self.relu3(h)\n",
    "        h = self.conv3(h)\n",
    "        y = torch.sigmoid(h)\n",
    "        return y\n",
    "    \n",
    "#一様乱数のノイズを生成する関数\n",
    "def gen_noise(batch_size):\n",
    "    return torch.empty(batch_size, 100).uniform_(0, 1).to(device)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # ランダムシードの固定\n",
    "    np.random.seed(1234)\n",
    "    torch.manual_seed(1234)\n",
    "    # 演算デバイスの設定、GPUが使用可能ならGPUを使用、そうでなければCPUを使用\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    #### 1. データの読み込み\n",
    "    # Fashion-MNIST: MNISTのファッションデータ\n",
    "    # 60,000 例のトレーニング セットと 10,000 例のテスト セット\n",
    "    # 28x28 グレースケール イメージで、10 クラスのラベル\n",
    "    root = os.path.join(os.path.dirname(__file__), '.', 'data', 'fashion_mnist')\n",
    "    # 複数の前処理を定義, 画像データをテンソルに変換する, 1次元のベクトルに変換するラムダ関数\n",
    "    transform = transforms.Compose([transforms.ToTensor(),lambda x: x.view(-1)])\n",
    "    # Fashion-MNISTのデータを前処理して、ダウンロードする\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root,\n",
    "                                                    download=True,\n",
    "                                                    train=True,\n",
    "                                                    transform=transform)\n",
    "    # 訓練データをバッチで取得するためのデータローダ\n",
    "    # 1つのバッチに含まれるサンプル数が100\n",
    "    train_dataloader = DataLoader(mnist_train,batch_size=100,shuffle=True)\n",
    "\n",
    "    #### 2. モデルの構築\n",
    "    # モデルの定義\n",
    "    model = GAN(device=device).to(device)\n",
    "\n",
    "    # 最適化手法の定義\n",
    "    # Adam(Adaptive moment): 適応的モーメント, モーメンタムとRMSPropを組み合わせて、鞍点に落ち込みにくく、学習率を0にしにくくしている\n",
    "    # Momentum: 運動量, 勾配に落ち込む際に加速度項を追加して、物理的な加速度を再現して、鞍点に落ち込むのを防ぐ作用\n",
    "    # AdaGrad(Adaptive Gradient): 適応的勾配, 重みwの学習率の自動調整, k方向の累積の修正量が多い場合はk方向の修正量を減らす作用\n",
    "    # RMS Prop: Root Mean Square Prop, 重みの移動平均, 過去の情報が指数関数的に薄まって作用\n",
    "    optimizer_D = optimizers.Adam(model.D.parameters(), lr=0.0002) # learning_rate: 学習率\n",
    "    optimizer_G = optimizers.Adam(model.G.parameters(), lr=0.0002)\n",
    "\n",
    "    # 損失関数の定義\n",
    "    # 交差エントロピー誤差　Binary Cross Entropy Loss {H(p, q) = -\\sum_{x} p(x) log(q(x))} 微分計算がしやすい\n",
    "    criterion = nn.BCELoss()\n",
    "    def compute_loss(label, preds):\n",
    "        return criterion(preds, label)\n",
    "\n",
    "    #### 3. モデルの訓練   \n",
    "    def train_step(x):\n",
    "        # 入力データのバッチサイズ\n",
    "        batch_size = x.size(0)\n",
    "        # 識別器と生成器の訓練モードを有効にする\n",
    "        model.D.train()\n",
    "        model.G.train()\n",
    "        # 識別器の訓練\n",
    "        # 784 次元のベクトルを 28x28 の画像に変更\n",
    "        # x.size() = 100 × 784の行列\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        # x.size() = 28 × 28の行列, チャンネル数1(グレースケール)\n",
    "        \n",
    "        # 入力データに対する推論をして、次元を削減して1次元のテンソルに変換\n",
    "        preds = model.D(x).squeeze() # 本物画像に対する予測\n",
    "        # 本物の画像に対する正解ラベルとして、サイズが batch_size の値1のテンソル\n",
    "        t = torch.ones(batch_size).float().to(device)\n",
    "        # 予測値 preds と本物正解ラベル t を用いて交差エントロピー誤差を計算\n",
    "        loss_D_real = compute_loss(t, preds)\n",
    "\n",
    "        # 偽物画像生成\n",
    "        noise = gen_noise(batch_size)\n",
    "        # 生成器モデルにノイズ noise を入力し、生成された偽物の画像\n",
    "        gen = model.G(noise)\n",
    "        # 生成器モデルにノイズ noise を入力し、生成された偽物の画像に対する推論, 生成器Gに勾配が伝わらないようにするため,detachしている。\n",
    "        preds = model.D(gen.detach()).squeeze()\n",
    "        # 偽物の画像に対する正解ラベルとして、サイズが batch_size の0のテンソル\n",
    "        t = torch.zeros(batch_size).float().to(device)\n",
    "        # 予測値 preds と偽物正解ラベル t を用いて交差エントロピー誤差を計算\n",
    "        loss_D_fake = compute_loss(t, preds)\n",
    "        \n",
    "        # 識別器と生成器の損失関数の合算\n",
    "        loss_D = loss_D_real + loss_D_fake\n",
    "        \n",
    "        # モデル内のパラメータの勾配を初期化して、識別機の学習\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # 生成器の学習\n",
    "        noise = gen_noise(batch_size)\n",
    "        gen = model.G(noise)\n",
    "        preds = model.D(gen).squeeze()\n",
    "        # 生成器の出力はすべて正解として損失関数を計算\n",
    "        t = torch.ones(batch_size).float().to(device)\n",
    "        loss_G = compute_loss(t, preds)\n",
    "        # モデル内のパラメータの勾配を初期化して、生成器の学習\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        return loss_D, loss_G\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        train_loss_D = 0.\n",
    "        train_loss_G = 0.\n",
    "        test_loss = 0.\n",
    "        for (x, _) in train_dataloader:\n",
    "            x = x.to(device)\n",
    "            loss_D, loss_G = train_step(x)\n",
    "            train_loss_D += loss_D.item()\n",
    "            train_loss_G += loss_G.item()\n",
    "        train_loss_D /= len(train_dataloader)\n",
    "        train_loss_G /= len(train_dataloader)\n",
    "        print('Epoch: {}, D Cost: {:.3f}, G Cost: {:.3f}'.format(epoch+1,train_loss_D,train_loss_G))\n",
    "\n",
    "    # モデルのパラメータのみを保存\n",
    "    torch.save(model.state_dict(), 'model_weight.pth')\n",
    "    # モデル全体を保存\n",
    "    torch.save(model, 'model.pth')\n",
    "\n",
    "    ### 4. Test model\n",
    "    # 保存したモデルの読み込み\n",
    "    model = GAN(device=device).to(device)\n",
    "    model.load_state_dict(torch.load('model_weight.pth'))\n",
    "    # 特定のバッチサイズで一様乱数の画像を生成して、生成器で推論する関数\n",
    "    def generate(batch_size=16):\n",
    "        model.eval()\n",
    "        noise = gen_noise(batch_size)\n",
    "        gen = model.G(noise)\n",
    "        return gen\n",
    "    images = generate(batch_size=16)\n",
    "    # 次元を削減して1次元のテンソルに変換して、GPUからCPUにデータを移動する\n",
    "    images = images.squeeze().detach().cpu().numpy()\n",
    "    # 生成した画像を一つのキャンバスに並べて表示する\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(image, cmap='binary_r')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(\"GAN-Fashion-MNIST.jpg\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
